{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GPflow\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "import copy\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# R magic\n",
    "import rpy2\n",
    "\n",
    "# the following lines will allow us to convert between Pandas DataFrames and R DataFrames\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects import pandas2ri\n",
    "pandas2ri.activate()\n",
    "from rpy2.robjects.conversion import ri2py\n",
    "\n",
    "# this loads the R magic extension\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Import CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_prior = np.genfromtxt(fname = \"data/for_composititional_analysis_prior.csv\", \n",
    "                     delimiter = ',',\n",
    "                     usecols = (1,2,3,4,5),\n",
    "                     skip_header = 1,\n",
    "                     dtype=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_posterior =  np.genfromtxt(fname = \"data/for_composititional_analysis_posterior.csv\", \n",
    "                                 delimiter = ',',\n",
    "                                 usecols = (1,2,3,4,5,6),\n",
    "                                 skip_header = 1,\n",
    "                                 dtype=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transformation of array to matrix\n",
    "def array_to_matrix(x):\n",
    "    X = []\n",
    "    for i in range(len(x)):\n",
    "        X.append([float(x[i])])\n",
    "    X = np.array(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Processes\n",
    "Docs:\n",
    "- [GP Regression](http://gpflow.readthedocs.io/en/latest/notebooks/regression.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute(X, Y, kernel_name):\n",
    "    # Get kernel\n",
    "    kernel = get_new_kernel(kernel_name)\n",
    "    \n",
    "    model = GPflow.gpr.GPR(X, Y, kern = kernel)\n",
    "    \n",
    "    try:\n",
    "        model.optimize()\n",
    "    except:\n",
    "        # Add white kernel\n",
    "        w = GPflow.kernels.White(1, variance = 0.05)\n",
    "        w.variance.fixed = True\n",
    "        model = GPflow.gpr.GPR(X, Y, kern = kernel + w)\n",
    "        \n",
    "        try:\n",
    "            print('Adding White Kernel to', kernel_name)\n",
    "            model.optimize()\n",
    "        except:\n",
    "            print('Exception caught computing', kernel_name)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lml(model):\n",
    "    \"\"\"Log marginal likelihood of a GP\"\"\"\n",
    "    \n",
    "    try:\n",
    "        return model.compute_log_likelihood()\n",
    "    except:\n",
    "        print('Exception caught in lml')\n",
    "        return -999999999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(gps, X):\n",
    "    predictions = {}\n",
    "    \n",
    "    # For every GP, build predictions\n",
    "    for key in gps.keys():\n",
    "        \n",
    "        try:\n",
    "            mean, var = gps[key].predict_y(X)\n",
    "        except:\n",
    "            print('Exception caught in predict')\n",
    "            mean, var = np.array([0]), np.array([0])\n",
    "        \n",
    "        predictions[key] = {'mean': mean.tolist(), \n",
    "                            'var': var.tolist()}\n",
    "        \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_new_kernel(kernel_string):\n",
    "    # Initial new non-optimized kernels\n",
    "    l = GPflow.kernels.Linear(1)\n",
    "    p = GPflow.kernels.PeriodicKernel(1)\n",
    "    r = GPflow.kernels.RBF(1)\n",
    "    \n",
    "    if   kernel_string == 'l': return l\n",
    "    elif kernel_string == 'p': return p\n",
    "    elif kernel_string == 'r': return r\n",
    "\n",
    "    elif kernel_string == 'l+r': return  l+r\n",
    "    elif kernel_string == 'l+p': return  l+p\n",
    "    elif kernel_string == 'p+r': return  p+r\n",
    "\n",
    "    elif kernel_string == 'l*r': return  l*r\n",
    "    elif kernel_string == 'l*p': return  l*p\n",
    "    elif kernel_string == 'p*r': return  p*r\n",
    "\n",
    "    elif kernel_string == 'l+r+p': return l+r+p\n",
    "    elif kernel_string == 'l+r*p': return l+r*p\n",
    "    elif kernel_string == 'l*r+p': return l*r+p\n",
    "    elif kernel_string == 'l*p+r': return l*p+r\n",
    "    elif kernel_string == 'l*r*p': return l*r*p\n",
    "    \n",
    "    else: return 'error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(Y):\n",
    "    std = np.std(Y)\n",
    "    mu = np.mean(Y)\n",
    "    \n",
    "    return ((Y - mu)/std)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_gps(X, Y0):\n",
    "    #Y = normalize(Y0)\n",
    "    Y = Y0\n",
    "    \n",
    "    gps = {}\n",
    "\n",
    "    gps['l'] = compute(X, Y, 'l')\n",
    "    gps['p'] = compute(X, Y, 'p')\n",
    "    gps['r'] = compute(X, Y, 'r')\n",
    "\n",
    "    gps['l+r'] = compute(X, Y, 'l+r')\n",
    "    gps['l+p'] = compute(X, Y, 'l+p')\n",
    "    gps['p+r'] = compute(X, Y, 'p+r')\n",
    "\n",
    "    gps['l*r'] = compute(X, Y, 'l*r')\n",
    "    gps['l*p'] = compute(X, Y, 'l*p')\n",
    "    gps['p*r'] = compute(X, Y, 'p*r')\n",
    "\n",
    "    gps['l+r+p'] = compute(X, Y, 'l+r+p')\n",
    "    gps['l+r*p'] = compute(X, Y, 'l+r*p')\n",
    "    gps['l*r+p'] = compute(X, Y, 'l*r+p')\n",
    "    gps['l*p+r'] = compute(X, Y, 'l*p+r')\n",
    "    gps['l*r*p'] = compute(X, Y, 'l*r*p')\n",
    "    \n",
    "    return gps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_lmls(models):\n",
    "    lmls = {}\n",
    "    for key in models.keys():\n",
    "        lmls[key] = lml(models[key])\n",
    "        \n",
    "    return lmls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gps_to_string(gps):\n",
    "    strings = {}\n",
    "    for key in gps.keys():\n",
    "        strings[key] = str(gps[key])\n",
    "        \n",
    "    return strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dict_max(d):\n",
    "    maxval = max(d.values())\n",
    "    keys = [k for k,v in d.items() if v==maxval]\n",
    "    return keys, maxval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_results(results, filename):\n",
    "    with open('output/' + filename + '.json', 'w') as fp:\n",
    "        json.dump(results, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xpredictions = np.linspace(31, 365*4, int(365*4-31+1))[:,None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Gaussian Process Models for a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_gps_for_dataset(dataset, Xpredictions=Xpredictions):\n",
    "    t0 = time.time()\n",
    "    \n",
    "    ids = np.unique(dataset['f0'])\n",
    "    \n",
    "    gpss_objects = {}\n",
    "    gpss = {}\n",
    "    predictions = {}\n",
    "    lmls = {}\n",
    "    maxs = {}\n",
    "    \n",
    "    for i in ids:\n",
    "        print(i)\n",
    "        # Filter the relevant data\n",
    "        filtered_data = dataset[dataset['f0'] == i]\n",
    "        \n",
    "        # Get X and Y\n",
    "        X = array_to_matrix(filtered_data['f3'])\n",
    "        Y = array_to_matrix(filtered_data['f4'])\n",
    "        \n",
    "        # Compute GPs\n",
    "        gps = compute_gps(X, Y)\n",
    "        print('Compute OK')\n",
    "        \n",
    "        # Calculate the predictions of the GP given the initial data\n",
    "        \n",
    "        # Find the best fitting GP\n",
    "        likelihoods = compute_lmls(gps)\n",
    "        best = dict_max(likelihoods)\n",
    "        print('LMLs OK')\n",
    "        \n",
    "        # Make predictions\n",
    "        gps_predictions = predict(gps, Xpredictions)\n",
    "        print('Predictions OK')\n",
    "        \n",
    "        # Save\n",
    "        i = str(i)\n",
    "        #gpss_objects[i] = gps\n",
    "        gpss[i] = gps_to_string(gps) # The GP parameters\n",
    "        predictions[i] = gps_predictions\n",
    "        lmls[i] = likelihoods\n",
    "        maxs[i] = best\n",
    "        \n",
    "\n",
    "    print('Minutes:', str(round((time.time() - t0) / 60)))\n",
    "        \n",
    "    return {\n",
    "            'gpss_objects': gpss_objects, #Actual objects\n",
    "            'gpss': gpss, \n",
    "            'Xpredictions': Xpredictions.tolist(), \n",
    "            'predictions': predictions, \n",
    "            'lmls': lmls, \n",
    "            'maxs': maxs\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot(X, Y, mean, var):\n",
    "    xx = Xpredictions\n",
    "    plt.clf()\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(X, Y, 'kx', mew=2)\n",
    "    plt.plot(xx, mean, 'b', lw=2)\n",
    "    plt.fill_between(xx[:,0], mean[:,0] - 2*np.sqrt(var[:,0]), mean[:,0] + 2*np.sqrt(var[:,0]), color='blue', alpha=0.2)\n",
    "    plt.xlim(31, 365*4)\n",
    "    #plt.ylim(-2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_predictions(results, data, target_id, target_kernel):\n",
    "\n",
    "    dat = data[data['f0'] == target_id]\n",
    "\n",
    "    X = array_to_matrix(dat['f3'])\n",
    "    Y = normalize(array_to_matrix(dat['f4']))\n",
    "\n",
    "    mean = np.array(results['predictions'][str(target_id)][target_kernel]['mean'])\n",
    "    var = np.array(results['predictions'][str(target_id)][target_kernel]['var'])\n",
    "\n",
    "    plot(X, Y, mean, var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Gaussian Processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def debug_filtering(dataset):\n",
    "    #dataset = dataset[dataset['f0'] == 59]\n",
    "    #dataset = dataset[dataset['f0'] > 10]\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scenario(dataset, scenario):\n",
    "    return dataset[dataset['f2'] == scenario]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'\"FB Friends\"', b'\"Gym members\"', b'\"Rain\"', b'\"Salary\"',\n",
       "       b'\"Sales\"', b'\"Temperature\"'], \n",
       "      dtype='|S13')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(data_prior['f2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prior condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = debug_filtering(data_prior)\n",
    "#results_prior = compute_gps_for_dataset(dataset)\n",
    "#save_results(results_prior, 'results_prior')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posterior condition (only evidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dataset = debug_filtering(data_posterior)\n",
    "\n",
    "# Only the evidence\n",
    "#dataset = dataset[dataset['f3'] < (365-31+1)]\n",
    "\n",
    "#results_posterior = compute_gps_for_dataset(dataset)\n",
    "#save_results(results_posterior, 'results_posterior')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_predictions(results_posterior, data_posterior, 8, 'l+p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_predictions(results_prior, data_prior, 9, 'l+r*p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "source(\"tools.R\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('output/results_prior.json', 'r') as fp:\n",
    "    results_prior = json.load(fp)\n",
    "    \n",
    "with open('output/results_posterior.json', 'r') as fp:\n",
    "    results_posterior = json.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proportions of best fitting kernel composition in the Prior condition, per scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxs_prior = pd.Series(results_prior['maxs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-68-904d31d9d068>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-68-904d31d9d068>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    %%R\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "%R -i maxs_prior\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%R \n",
    "a<-c(1,2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  2.,  3.])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%R a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEBUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_prior['maxs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['maxs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
