{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import GPflow\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "import copy\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Import CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_prior = np.genfromtxt(fname = \"data/for_composititional_analysis_prior_v.csv\", \n",
    "                     delimiter = ',',\n",
    "                     usecols = (1,2,3,4,5),\n",
    "                     skip_header = 1,\n",
    "                     dtype=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_posterior =  np.genfromtxt(fname = \"data/for_composititional_analysis_posterior.csv\", \n",
    "                                 delimiter = ',',\n",
    "                                 usecols = (1,2,3,4,5,6),\n",
    "                                 skip_header = 1,\n",
    "                                 dtype=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transformation of array to matrix\n",
    "def array_to_matrix(x):\n",
    "    X = []\n",
    "    for i in range(len(x)):\n",
    "        X.append([float(x[i])])\n",
    "    X = np.array(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Processes\n",
    "Docs:\n",
    "- [GP Regression](http://gpflow.readthedocs.io/en/latest/notebooks/regression.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute(X, Y, kernel_name):\n",
    "    # Get kernel\n",
    "    kernel = get_new_kernel(kernel_name)\n",
    "    \n",
    "    model = GPflow.gpr.GPR(X, Y, kern = kernel)\n",
    "    \n",
    "    try:\n",
    "        model.optimize()\n",
    "    except:\n",
    "        # Add white kernel\n",
    "        w = GPflow.kernels.White(1, variance = 0.05)\n",
    "        w.variance.fixed = True\n",
    "        model = GPflow.gpr.GPR(X, Y, kern = kernel + w)\n",
    "        \n",
    "        try:\n",
    "            print('Adding White Kernel to', kernel_name)\n",
    "            model.optimize()\n",
    "        except:\n",
    "            print('Exception caught computing', kernel_name)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lml(model):\n",
    "    \"\"\"Log marginal likelihood of a GP\"\"\"\n",
    "    \n",
    "    try:\n",
    "        return model.compute_log_likelihood()\n",
    "    except:\n",
    "        print('Exception caught in lml')\n",
    "        return -999999999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_new_kernel(kernel_string):\n",
    "    # Initial new non-optimized kernels\n",
    "    l = GPflow.kernels.Linear(1)\n",
    "    p = GPflow.kernels.PeriodicKernel(1)\n",
    "    r = GPflow.kernels.RBF(1)\n",
    "    \n",
    "    if   kernel_string == 'l': return l\n",
    "    elif kernel_string == 'p': return p\n",
    "    elif kernel_string == 'r': return r\n",
    "\n",
    "    elif kernel_string == 'l+r': return  l+r\n",
    "    elif kernel_string == 'l+p': return  l+p\n",
    "    elif kernel_string == 'p+r': return  p+r\n",
    "\n",
    "    elif kernel_string == 'l*r': return  l*r\n",
    "    elif kernel_string == 'l*p': return  l*p\n",
    "    elif kernel_string == 'p*r': return  p*r\n",
    "\n",
    "    elif kernel_string == 'l+r+p': return l+r+p\n",
    "    elif kernel_string == 'l+r*p': return l+r*p\n",
    "    elif kernel_string == 'l*r+p': return l*r+p\n",
    "    elif kernel_string == 'l*p+r': return l*p+r\n",
    "    elif kernel_string == 'l*r*p': return l*r*p\n",
    "    \n",
    "    else: return 'error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(Y):\n",
    "    std = np.std(Y)\n",
    "    mu = np.mean(Y)\n",
    "    \n",
    "    return ((Y - mu)/std)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_gps(X, Y0):\n",
    "    Y = normalize(Y0)\n",
    "    \n",
    "    gps = {}\n",
    "\n",
    "    gps['l'] = compute(X, Y, 'l')\n",
    "    gps['p'] = compute(X, Y, 'p')\n",
    "    gps['r'] = compute(X, Y, 'r')\n",
    "\n",
    "    gps['l+r'] = compute(X, Y, 'l+r')\n",
    "    gps['l+p'] = compute(X, Y, 'l+p')\n",
    "    gps['p+r'] = compute(X, Y, 'p+r')\n",
    "\n",
    "    gps['l*r'] = compute(X, Y, 'l*r')\n",
    "    gps['l*p'] = compute(X, Y, 'l*p')\n",
    "    gps['p*r'] = compute(X, Y, 'p*r')\n",
    "\n",
    "    gps['l+r+p'] = compute(X, Y, 'l+r+p')\n",
    "    gps['l+r*p'] = compute(X, Y, 'l+r*p')\n",
    "    gps['l*r+p'] = compute(X, Y, 'l*r+p')\n",
    "    gps['l*p+r'] = compute(X, Y, 'l*p+r')\n",
    "    gps['l*r*p'] = compute(X, Y, 'l*r*p')\n",
    "    \n",
    "    return gps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_lmls(models):\n",
    "    lmls = {}\n",
    "    for key in models.keys():\n",
    "        lmls[key] = lml(models[key])\n",
    "        \n",
    "    return lmls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gps_to_string(gps):\n",
    "    strings = {}\n",
    "    for key in gps.keys():\n",
    "        strings[key] = str(gps[key])\n",
    "        \n",
    "    return strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dict_max(d):\n",
    "    maxval = max(d.values())\n",
    "    keys = [k for k,v in d.items() if v==maxval]\n",
    "    return keys, maxval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_results(results, filename):\n",
    "    with open('output/' + filename + '.json', 'w') as fp:\n",
    "        json.dump(results, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(gps, X):\n",
    "    predictions = {}\n",
    "    \n",
    "    # For every GP, build predictions\n",
    "    for key in gps.keys():\n",
    "        mean, var = gps[key].predict_y(X)\n",
    "        \n",
    "        predictions[key] = {'mean': mean.tolist(), \n",
    "                            'var': var.tolist()}\n",
    "        \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xpredictions = np.linspace(31, 365*4, int(365*4-31+1))[:,None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Gaussian Process Models for a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gps_for_dataset(dataset, Xpredictions=Xpredictions):\n",
    "    \n",
    "    ids = np.unique(dataset['f0'])\n",
    "    \n",
    "    gpss_objects = {}\n",
    "    gpss = {}\n",
    "    predictions = {}\n",
    "    lmls = {}\n",
    "    maxs = {}\n",
    "    \n",
    "    for i in ids:\n",
    "        print(i)\n",
    "        # Filter the relevant data\n",
    "        filtered_data = dataset[dataset['f0'] == i]\n",
    "        \n",
    "        # Get X and Y\n",
    "        X = array_to_matrix(filtered_data['f3'])\n",
    "        Y = array_to_matrix(filtered_data['f4'])\n",
    "        \n",
    "        # Compute GPs\n",
    "        gps = compute_gps(X, Y)\n",
    "        print('Compute OK')\n",
    "        \n",
    "        # Calculate the predictions of the GP given the initial data\n",
    "        \n",
    "        # Find the best fitting GP\n",
    "        likelihoods = compute_lmls(gps)\n",
    "        best = dict_max(likelihoods)\n",
    "        print('LMLs OK')\n",
    "        \n",
    "        # Make predictions\n",
    "        gps_predictions = predict(gps, Xpredictions)\n",
    "        print('Predictions OK')\n",
    "        \n",
    "        # Save\n",
    "        i = str(i)\n",
    "        gpss_objects[i] = gps\n",
    "        gpss[i] = gps_to_string(gps) # The GP parameters\n",
    "        predictions[i] = gps_predictions\n",
    "        lmls[i] = likelihoods\n",
    "        maxs[i] = best\n",
    "        \n",
    "    return {\n",
    "            #'gpss_objects': gpss_objects, #Actual objects\n",
    "            'gpss': gpss, \n",
    "            'Xpredictions': Xpredictions.tolist(), \n",
    "            'predictions': predictions, \n",
    "            'lmls': lmls, \n",
    "            'maxs': maxs\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot(X, Y, mean, var):\n",
    "    xx = Xpredictions\n",
    "    plt.clf()\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(X, Y, 'kx', mew=2)\n",
    "    plt.plot(xx, mean, 'b', lw=2)\n",
    "    plt.fill_between(xx[:,0], mean[:,0] - 2*np.sqrt(var[:,0]), mean[:,0] + 2*np.sqrt(var[:,0]), color='blue', alpha=0.2)\n",
    "    plt.xlim(31, 365*4)\n",
    "    #plt.ylim(-2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(results, data, target_id, target_kernel):\n",
    "\n",
    "    dat = data[data['f0'] == target_id]\n",
    "\n",
    "    X = array_to_matrix(dat['f3'])\n",
    "    Y = normalize(array_to_matrix(dat['f4']))\n",
    "\n",
    "    mean = np.array(results['predictions'][str(target_id)][target_kernel]['mean'])\n",
    "    var = np.array(results['predictions'][str(target_id)][target_kernel]['var'])\n",
    "\n",
    "    plot(X, Y, mean, var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Gaussian Processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prior condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "Adding White Kernel to l+r*p\n",
      "Adding White Kernel to l*p+r\n",
      "Compute OK\n",
      "LMLs OK\n",
      "Predictions OK\n",
      "9\n",
      "Adding White Kernel to l+r+p\n",
      "Adding White Kernel to l+r*p\n",
      "Adding White Kernel to l*p+r\n",
      "Compute OK\n",
      "LMLs OK\n",
      "Predictions OK\n",
      "10\n",
      "Adding White Kernel to p*r\n",
      "Adding White Kernel to l+r+p\n",
      "Adding White Kernel to l+r*p\n",
      "Compute OK\n",
      "LMLs OK\n",
      "Predictions OK\n"
     ]
    }
   ],
   "source": [
    "dataset = data_prior\n",
    "\n",
    "dataset = dataset[dataset['f0'] < 11]\n",
    "dataset = dataset[dataset['f0'] > 7]\n",
    "\n",
    "results_prior = compute_gps_for_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_results(results_prior, 'results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posterior condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the data\n",
    "temperature = data[data['f2'] == b'\"Temperature\"']\n",
    "rain = data[data['f2'] == b'\"Rain\"']\n",
    "sales = data[data['f2'] == b'\"Sales\"']\n",
    "salary = data[data['f2'] == b'\"Salary\"']\n",
    "gym = data[data['f2'] == b'\"Gym members\"']\n",
    "fb = data[data['f2'] == b'\"FB Friends\"']\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "# Temperature\n",
    "prior_temperature = compute_gps_for_dataset(temperature)\n",
    "\n",
    "# Rain\n",
    "prior_rain = compute_gps_for_dataset(rain)\n",
    "\n",
    "# Sales\n",
    "prior_sales = compute_gps_for_dataset(sales)\n",
    "\n",
    "# Salary\n",
    "prior_salary = compute_gps_for_dataset(salary)\n",
    "\n",
    "# Gym\n",
    "prior_gym = compute_gps_for_dataset(gym)\n",
    "\n",
    "# Facebook\n",
    "prior_fb = compute_gps_for_dataset(fb)\n",
    "\n",
    "t1 = time.time()\n",
    "(t1-t0)/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save\n",
    "save_results(prior_temperature, 'prior_temperature')\n",
    "save_results(prior_rain, 'prior_rain')\n",
    "save_results(prior_sales, 'prior_sales')\n",
    "save_results(prior_salary, 'prior_salary')\n",
    "save_results(prior_gym, 'prior_gym')\n",
    "save_results(prior_fb, 'prior_fb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEBUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot(m, X, Y):\n",
    "    xx = np.linspace(31, 365*4, int(365*4-31+1))[:,None]\n",
    "    mean, var = m.predict_y(xx)\n",
    "    plt.clf()\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(X, Y, 'kx', mew=2)\n",
    "    plt.plot(xx, mean, 'b', lw=2)\n",
    "    plt.fill_between(xx[:,0], mean[:,0] - 2*np.sqrt(var[:,0]), mean[:,0] + 2*np.sqrt(var[:,0]), color='blue', alpha=0.2)\n",
    "    plt.xlim(31, 365*4)\n",
    "    plt.ylim(-2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "curve_id = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "one_combination = data[data['f0'] < 3]\n",
    "results = compute_gps_for_dataset(one_combination)\n",
    "\n",
    "t1 = time.time()\n",
    "(t1-t0)/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['predictions'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the same kernel composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_evidence(curve_id):\n",
    "    dataset = posterior_data\n",
    "\n",
    "    # Filter the relevant data\n",
    "    filtered_data = dataset[dataset['f0'] == curve_id]\n",
    "\n",
    "    # Get X and Y\n",
    "    X = array_to_matrix(filtered_data['f3'])\n",
    "    Y = array_to_matrix(filtered_data['f4'])\n",
    "\n",
    "    #\n",
    "    Xe = X[1:n] \n",
    "    Ye = Y[1:n]\n",
    "\n",
    "    return (Xe, Ye)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best fitting kernel composition (string)\n",
    "best_kernel_name = results['maxs'][curve_id][0][0]\n",
    "\n",
    "# Get the evidence for the subject\n",
    "\n",
    "# Create a new kernel using that composition\n",
    "Xe, Ye = get_evidence(curve_id)\n",
    "gp = compute(Xe, Ye, best_kernel_name)\n",
    "\n",
    "# Fit it to the evidence shown in the Posterior condition\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = str(gp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best fitting kernel\n",
    "k = copy.deepcopy(results['gpss_objects'][subject][results['maxs'][subject][0][0]])\n",
    "\n",
    "#Specific (any other) kernel\n",
    "k = copy.deepcopy(results['gpss_objects'][subject]['l+r*p'])\n",
    "\n",
    "# Use the posterior data\n",
    "usePosterior = True\n",
    "\n",
    "if(usePosterior):\n",
    "    dataset = posterior_data\n",
    "else:\n",
    "    dataset = data\n",
    "\n",
    "\n",
    "# Filter the relevant data\n",
    "filtered_data = dataset[dataset['f0'] == subject]\n",
    "\n",
    "# Get X and Y\n",
    "X = array_to_matrix(filtered_data['f3'])\n",
    "Y = array_to_matrix(filtered_data['f4'])\n",
    "\n",
    "\n",
    "if(usePosterior):\n",
    "    # Evidence\n",
    "    n = 68\n",
    "    Xe = X[1:n] \n",
    "    Ye = Y[1:n]\n",
    "    k.X = Xe\n",
    "    k.Y = Ye\n",
    "    #k.optimize()\n",
    "    \n",
    "    #k.Y = np.concatenate([Ye, k.Y.value[68:]])\n",
    "    \n",
    "    \n",
    "# Plot\n",
    "plot(k, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name.likelihood.variance = 0.01\n",
    "\n",
    "k.optimize()\n",
    "k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prior magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = posterior_data\n",
    "\n",
    "# Filter the relevant data\n",
    "filtered_data = dataset[dataset['f0'] == subject]\n",
    "\n",
    "# Get X and Y\n",
    "X = array_to_matrix(filtered_data['f3'])\n",
    "Y = array_to_matrix(filtered_data['f4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 68 #68\n",
    "Xevidence = X[1:n] \n",
    "Yevidence = Y[1:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prior model\n",
    "m = results['gpss_objects'][subject]['l+p']\n",
    "\n",
    "# New model\n",
    "l = GPflow.kernels.Linear(1)\n",
    "p = GPflow.kernels.PeriodicKernel(1)\n",
    "r = GPflow.kernels.RBF(1)\n",
    "m2 = GPflow.gpr.GPR(Xevidence, Yevidence, kern=l+p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if(False):\n",
    "    # Transfer the parameters\n",
    "    m2.kern.linear.variance.prior = GPflow.priors.Gaussian(m.kern.linear.variance.value, m.kern.linear.variance.value)\n",
    "    \n",
    "    m2.kern.periodickernel.lengthscales.prior = GPflow.priors.Gaussian(m.kern.periodickernel.lengthscales.value, m.kern.periodickernel.lengthscales.value)\n",
    "    m2.kern.periodickernel.period.prior = GPflow.priors.Gaussian(m.kern.periodickernel.period.value, m.kern.periodickernel.period.value)\n",
    "    m2.kern.periodickernel.variance.prior = GPflow.priors.Gaussian(m.kern.periodickernel.variance.value, m.kern.periodickernel.variance.value)\n",
    "    \n",
    "    m2.kern.rbf.lengthscales.prior = GPflow.priors.Gaussian(m.kern.rbf.lengthscales.value, m.kern.rbf.lengthscales.value)\n",
    "    m2.kern.rbf.variance.prior = GPflow.priors.Gaussian(m.kern.rbf.variance.value, m.kern.rbf.variance.value)\n",
    "    \n",
    "    m2.likelihood.variance.prior = GPflow.priors.Gaussian(m.likelihood.variance.value, m.likelihood.variance.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if(True):\n",
    "    m2.kern.linear.variance = m.kern.linear.variance.value\n",
    "    \n",
    "    m2.kern.prod.periodickernel.lengthscales = m.kern.prod.periodickernel.lengthscales.value\n",
    "    m2.kern.prod.periodickernel.period = m.kern.prod.periodickernel.period.value\n",
    "    m2.kern.prod.periodickernel.variance = m.kern.prod.periodickernel.variance.value\n",
    "    \n",
    "    m2.kern.prod.rbf.lengthscales = m.kern.prod.rbf.lengthscales.value\n",
    "    m2.kern.prod.rbf.variance = m.kern.prod.rbf.variance.value\n",
    "    \n",
    "    m2.likelihood.variance = m.likelihood.variance.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#m2.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(m2, X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior by itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data\n",
    "\n",
    "# Filter the relevant data\n",
    "filtered_data = dataset[dataset['f0'] == 19]\n",
    "\n",
    "# Get X and Y\n",
    "X = array_to_matrix(filtered_data['f3'])\n",
    "Y = array_to_matrix(filtered_data['f4'])\n",
    "\n",
    "n = 68 #68\n",
    "Xe = X[1:n] \n",
    "Ye = Y[1:n]\n",
    "\n",
    "# New model\n",
    "l = GPflow.kernels.Linear(1)\n",
    "p = GPflow.kernels.PeriodicKernel(1)\n",
    "r = GPflow.kernels.RBF(1)\n",
    "m2 = GPflow.gpr.GPR(Xe, Ye, kern=(l*r+p))\n",
    "\n",
    "m2.optimize()\n",
    "\n",
    "plot(m2, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lml(m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
