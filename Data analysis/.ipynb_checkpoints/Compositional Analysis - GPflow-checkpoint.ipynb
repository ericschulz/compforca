{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import GPflow\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "#import tensorflow as tf\n",
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "import copy\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# R magic\n",
    "import rpy2\n",
    "\n",
    "\n",
    "# the following lines will allow us to convert between Pandas DataFrames and R DataFrames\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects import pandas2ri\n",
    "pandas2ri.activate()\n",
    "from rpy2.robjects.conversion import ri2py\n",
    "\n",
    "# this loads the R magic extension\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Import CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_prior = np.genfromtxt(fname = \"data/for_composititional_analysis_prior.csv\", \n",
    "                     delimiter = ',',\n",
    "                     usecols = (1,2,3,4,5),\n",
    "                     skip_header = 1,\n",
    "                     dtype=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_posterior =  np.genfromtxt(fname = \"data/for_composititional_analysis_posterior.csv\", \n",
    "                                 delimiter = ',',\n",
    "                                 usecols = (1,2,3,4,5,6),\n",
    "                                 skip_header = 1,\n",
    "                                 dtype=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transformation of array to matrix\n",
    "def array_to_matrix(x):\n",
    "    X = []\n",
    "    for i in range(len(x)):\n",
    "        X.append([float(x[i])])\n",
    "    X = np.array(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Processes\n",
    "Docs:\n",
    "- [GP Regression](http://gpflow.readthedocs.io/en/latest/notebooks/regression.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute(X, Y, kernel_name):\n",
    "    # Get kernel\n",
    "    kernel = get_new_kernel(kernel_name)\n",
    "    \n",
    "    model = GPflow.gpr.GPR(X, Y, kern = kernel)\n",
    "    \n",
    "    try:\n",
    "        model.optimize()\n",
    "    except:\n",
    "        # Add white kernel\n",
    "        w = GPflow.kernels.White(1, variance = 0.05)\n",
    "        w.variance.fixed = True\n",
    "        model = GPflow.gpr.GPR(X, Y, kern = kernel + w)\n",
    "        \n",
    "        try:\n",
    "            print('Adding White Kernel to', kernel_name)\n",
    "            model.optimize()\n",
    "        except:\n",
    "            print('Exception caught computing', kernel_name)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lml(model):\n",
    "    \"\"\"Log marginal likelihood of a GP\"\"\"\n",
    "    \n",
    "    try:\n",
    "        return model.compute_log_likelihood()\n",
    "    except:\n",
    "        print('Exception caught in lml')\n",
    "        return -999999999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(gps, X):\n",
    "    predictions = {}\n",
    "    \n",
    "    # For every GP, build predictions\n",
    "    for key in gps.keys():\n",
    "        \n",
    "        try:\n",
    "            mean, var = gps[key].predict_y(X)\n",
    "        except:\n",
    "            print('Exception caught in predict')\n",
    "            mean, var = np.array([0]), np.array([0])\n",
    "        \n",
    "        predictions[key] = {'mean': mean.tolist(), \n",
    "                            'var': var.tolist()}\n",
    "        \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_new_kernel(kernel_string):\n",
    "    # Initial new non-optimized kernels\n",
    "    l = GPflow.kernels.Linear(1)\n",
    "    p = GPflow.kernels.PeriodicKernel(1)\n",
    "    r = GPflow.kernels.RBF(1)\n",
    "    \n",
    "    if   kernel_string == 'l': return l\n",
    "    elif kernel_string == 'p': return p\n",
    "    elif kernel_string == 'r': return r\n",
    "\n",
    "    elif kernel_string == 'l+r': return  l+r\n",
    "    elif kernel_string == 'l+p': return  l+p\n",
    "    elif kernel_string == 'p+r': return  p+r\n",
    "\n",
    "    elif kernel_string == 'l*r': return  l*r\n",
    "    elif kernel_string == 'l*p': return  l*p\n",
    "    elif kernel_string == 'p*r': return  p*r\n",
    "\n",
    "    elif kernel_string == 'l+r+p': return l+r+p\n",
    "    elif kernel_string == 'l+r*p': return l+r*p\n",
    "    elif kernel_string == 'l*r+p': return l*r+p\n",
    "    elif kernel_string == 'l*p+r': return l*p+r\n",
    "    elif kernel_string == 'l*r*p': return l*r*p\n",
    "    \n",
    "    else: return 'error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(Y):\n",
    "    std = np.std(Y)\n",
    "    mu = np.mean(Y)\n",
    "    \n",
    "    return ((Y - mu)/std)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_gps(X, Y0):\n",
    "    #Y = normalize(Y0)\n",
    "    Y = Y0\n",
    "    \n",
    "    gps = {}\n",
    "\n",
    "    gps['l'] = compute(X, Y, 'l')\n",
    "    gps['p'] = compute(X, Y, 'p')\n",
    "    gps['r'] = compute(X, Y, 'r')\n",
    "\n",
    "    gps['l+r'] = compute(X, Y, 'l+r')\n",
    "    gps['l+p'] = compute(X, Y, 'l+p')\n",
    "    gps['p+r'] = compute(X, Y, 'p+r')\n",
    "\n",
    "    gps['l*r'] = compute(X, Y, 'l*r')\n",
    "    gps['l*p'] = compute(X, Y, 'l*p')\n",
    "    gps['p*r'] = compute(X, Y, 'p*r')\n",
    "\n",
    "    gps['l+r+p'] = compute(X, Y, 'l+r+p')\n",
    "    gps['l+r*p'] = compute(X, Y, 'l+r*p')\n",
    "    gps['l*r+p'] = compute(X, Y, 'l*r+p')\n",
    "    gps['l*p+r'] = compute(X, Y, 'l*p+r')\n",
    "    gps['l*r*p'] = compute(X, Y, 'l*r*p')\n",
    "    \n",
    "    return gps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_lmls(models):\n",
    "    lmls = {}\n",
    "    for key in models.keys():\n",
    "        lmls[key] = lml(models[key])\n",
    "        \n",
    "    return lmls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gps_to_string(gps):\n",
    "    strings = {}\n",
    "    for key in gps.keys():\n",
    "        strings[key] = str(gps[key])\n",
    "        \n",
    "    return strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dict_max(d):\n",
    "    maxval = max(d.values())\n",
    "    keys = [k for k,v in d.items() if v==maxval]\n",
    "    return keys, maxval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_results(results, filename):\n",
    "    with open('output/' + filename + '.json', 'w') as fp:\n",
    "        json.dump(results, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xpredictions = np.linspace(31, 365*4, int(365*4-31+1))[:,None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Gaussian Process Models for a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_gps_for_dataset(dataset, Xpredictions=Xpredictions):\n",
    "    t0 = time.time()\n",
    "    \n",
    "    ids = np.unique(dataset['f0'])\n",
    "    \n",
    "    gpss_objects = {}\n",
    "    gpss = {}\n",
    "    predictions = {}\n",
    "    lmls = {}\n",
    "    maxs = {}\n",
    "    \n",
    "    for i in ids:\n",
    "        print(i)\n",
    "        # Filter the relevant data\n",
    "        filtered_data = dataset[dataset['f0'] == i]\n",
    "        \n",
    "        # Get X and Y\n",
    "        X = array_to_matrix(filtered_data['f3'])\n",
    "        Y = array_to_matrix(filtered_data['f4'])\n",
    "        \n",
    "        # Compute GPs\n",
    "        gps = compute_gps(X, Y)\n",
    "        print('Compute OK')\n",
    "        \n",
    "        # Calculate the predictions of the GP given the initial data\n",
    "        \n",
    "        # Find the best fitting GP\n",
    "        likelihoods = compute_lmls(gps)\n",
    "        best = dict_max(likelihoods)\n",
    "        print('LMLs OK')\n",
    "        \n",
    "        # Make predictions\n",
    "        gps_predictions = predict(gps, Xpredictions)\n",
    "        print('Predictions OK')\n",
    "        \n",
    "        # Save\n",
    "        i = str(i)\n",
    "        #gpss_objects[i] = gps\n",
    "        gpss[i] = gps_to_string(gps) # The GP parameters\n",
    "        predictions[i] = gps_predictions\n",
    "        lmls[i] = likelihoods\n",
    "        maxs[i] = best\n",
    "        \n",
    "\n",
    "    print('Minutes:', str(round((time.time() - t0) / 60)))\n",
    "        \n",
    "    return {\n",
    "            'gpss_objects': gpss_objects, #Actual objects\n",
    "            'gpss': gpss, \n",
    "            'Xpredictions': Xpredictions.tolist(), \n",
    "            'predictions': predictions, \n",
    "            'lmls': lmls, \n",
    "            'maxs': maxs\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot(X, Y, mean, var):\n",
    "    xx = Xpredictions\n",
    "    plt.clf()\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(X, Y, 'kx', mew=2)\n",
    "    plt.plot(xx, mean, 'b', lw=2)\n",
    "    plt.fill_between(xx[:,0], mean[:,0] - 2*np.sqrt(var[:,0]), mean[:,0] + 2*np.sqrt(var[:,0]), color='blue', alpha=0.2)\n",
    "    plt.xlim(31, 365*4)\n",
    "    #plt.ylim(-2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_predictions(results, data, target_id, target_kernel):\n",
    "\n",
    "    dat = data[data['f0'] == target_id]\n",
    "\n",
    "    X = array_to_matrix(dat['f3'])\n",
    "    Y = normalize(array_to_matrix(dat['f4']))\n",
    "\n",
    "    mean = np.array(results['predictions'][str(target_id)][target_kernel]['mean'])\n",
    "    var = np.array(results['predictions'][str(target_id)][target_kernel]['var'])\n",
    "\n",
    "    plot(X, Y, mean, var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Gaussian Processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def debug_filtering(dataset):\n",
    "    #dataset = dataset[dataset['f0'] == 59]\n",
    "    #dataset = dataset[dataset['f0'] > 10]\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scenario(dataset, scenario):\n",
    "    return dataset[dataset['f2'] == scenario]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.unique(data_prior['f2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prior condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dataset = debug_filtering(data_prior)\n",
    "#results_prior = compute_gps_for_dataset(dataset)\n",
    "#save_results(results_prior, 'results_prior')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posterior condition (only evidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dataset = debug_filtering(data_posterior)\n",
    "\n",
    "# Only the evidence\n",
    "#dataset = dataset[dataset['f3'] < (365-31+1)]\n",
    "\n",
    "#results_posterior = compute_gps_for_dataset(dataset)\n",
    "#save_results(results_posterior, 'results_posterior')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_predictions(results_posterior, data_posterior, 8, 'l+p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_predictions(results_prior, data_prior, 9, 'l+r*p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qv/anaconda3/lib/python3.6/site-packages/rpy2/rinterface/__init__.py:186: RRuntimeWarning: Loading tidyverse: ggplot2\n",
      "Loading tidyverse: tibble\n",
      "Loading tidyverse: tidyr\n",
      "Loading tidyverse: readr\n",
      "Loading tidyverse: purrr\n",
      "Loading tidyverse: dplyr\n",
      "\n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/home/qv/anaconda3/lib/python3.6/site-packages/rpy2/rinterface/__init__.py:186: RRuntimeWarning: Conflicts with tidy packages ---------------------------------------------------\n",
      "\n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/home/qv/anaconda3/lib/python3.6/site-packages/rpy2/rinterface/__init__.py:186: RRuntimeWarning: arrange():   dplyr, plyr\n",
      "compact():   purrr, plyr\n",
      "count():     dplyr, plyr\n",
      "failwith():  dplyr, plyr\n",
      "filter():    dplyr, stats\n",
      "id():        dplyr, plyr\n",
      "lag():       dplyr, stats\n",
      "mutate():    dplyr, plyr\n",
      "rename():    dplyr, plyr\n",
      "summarise(): dplyr, plyr\n",
      "summarize(): dplyr, plyr\n",
      "\n",
      "  warnings.warn(x, RRuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "source(\"tools.R\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('output/results_prior.json', 'r') as fp:\n",
    "    results_prior = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('output/results_posterior.json', 'r') as fp:\n",
    "    results_posterior = json.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to analyze data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "kernels <- c(\"l\", \"p\", \"r\", \"l+p\", \"l+r\", \"p+r\", \"l*r\", \"l*p\", \"p*r\", \"l+r+p\", \"l+r*p\", \"l*r+p\", \"l*p+r\", \"l*r*p\")\n",
    "\n",
    "get_proportions <- function(res_x) {\n",
    "    total <- length(res_x[1][[1]])\n",
    "\n",
    "    props <- res_x %>% \n",
    "                group_by(kernel) %>%\n",
    "                summarize(proportion = length(kernel)/total)\n",
    "    \n",
    "    props$kernel <- factor(props$kernel, levels=kernels)\n",
    "    \n",
    "    # Adding zeros\n",
    "    for (k in kernels){\n",
    "        # If the kernel is NOT present\n",
    "        if (sum(props$kernel == k) == 0){\n",
    "            new_row <- c(k, 0)\n",
    "            \n",
    "            props <- rbind(props, new_row)\n",
    "        } \n",
    "    }\n",
    "    \n",
    "    # Reorder factors\n",
    "    #props$kernel <- factor(props$kernel, levels=c(\"l\", \"p\", \"r\", \"l+p\", \"l+r\", \"p+r\", \"l*r\", \"l*p\", \"p*r\", \"l+r+p\", \"l+r*p\", \"l*r+p\", \"l*p+r\", \"l*r*p\"))\n",
    "    \n",
    "    props$proportion <- as.numeric(props$proportion)\n",
    "    \n",
    "    return (props)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "plot_proportions <- function(prop_data, title, hide_x=FALSE, hide_y=FALSE) {\n",
    "    plot <- prop_data %>%\n",
    "                ggplot(aes(x=kernel, y=proportion)) + \n",
    "                    geom_bar(stat=\"identity\") +\n",
    "                    ylim(0, 0.5) +\n",
    "                    labs(title = title) +\n",
    "                    #ggthemes::theme_few() +\n",
    "                    xlab(\"Kernel composition\") + ylab(\"Proportion\") +\n",
    "                    theme(axis.text.x = element_text(angle = 90,  vjust = 0.5, hjust=0),\n",
    "                          text = element_text(size=12, family=\"serif\"),\n",
    "                          plot.title = element_text(hjust = 0.5))\n",
    "    \n",
    "    if(hide_x){\n",
    "        plot <- plot + theme(axis.title.x=element_blank())\n",
    "    }\n",
    "    if(hide_y){\n",
    "        plot <- plot + theme(axis.title.y=element_blank())\n",
    "    }\n",
    "    \n",
    "    return(plot)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proportions of best fitting kernel composition in the Prior condition, per scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxs_prior = pd.DataFrame(data=results_prior['maxs']).T\n",
    "maxs_prior.columns = ['kernel', 'lml']\n",
    "\n",
    "for i in maxs_prior.index:\n",
    "    maxs_prior['kernel'][i] = maxs_prior['kernel'][i][0]\n",
    "    \n",
    "maxs_prior['id'] = maxs_prior.index.values.tolist()\n",
    "\n",
    "maxs_prior_i = maxs_prior['id'].values.tolist()\n",
    "maxs_prior_k = maxs_prior['kernel'].values.tolist()\n",
    "maxs_prior_l = maxs_prior['lml'].values.tolist()\n",
    "\n",
    "#maxs_posterior =  = pd.Series(results_posterior['maxs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qv/anaconda3/lib/python3.6/site-packages/rpy2/rinterface/__init__.py:186: RRuntimeWarning: Parsed with column specification:\n",
      "cols(\n",
      "  X1 = col_integer(),\n",
      "  id = col_integer(),\n",
      "  pid = col_character(),\n",
      "  scenario = col_character(),\n",
      "  x = col_integer(),\n",
      "  y = col_double()\n",
      ")\n",
      "\n",
      "  warnings.warn(x, RRuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\r",
       "|                                                                        |   0%\r",
       "|=                                                                       |   1%\r",
       "|=                                                                       |   2%\r",
       "|==                                                                      |   3%\r",
       "|==                                                                      |   3%\r",
       "|===                                                                     |   4%\r",
       "|====                                                                    |   5%\r",
       "|====                                                                    |   6%\r",
       "|=====                                                                   |   7%\r",
       "|=====                                                                   |   7%\r",
       "|======                                                                  |   8%\r",
       "|======                                                                  |   9%\r",
       "|=======                                                                 |  10%\r",
       "|========                                                                |  11%\r",
       "|=======                                                         |  11%    1 MB\r",
       "|========                                                        |  12%    1 MB\r",
       "|========                                                        |  13%    1 MB\r",
       "|=========                                                       |  14%    1 MB\r",
       "|=========                                                       |  15%    1 MB\r",
       "|==========                                                      |  16%    1 MB\r",
       "|===========                                                     |  16%    1 MB\r",
       "|===========                                                     |  17%    1 MB\r",
       "|============                                                    |  18%    1 MB\r",
       "|============                                                    |  19%    1 MB\r",
       "|=============                                                   |  20%    1 MB\r",
       "|=============                                                   |  21%    1 MB\r",
       "|==============                                                  |  21%    1 MB\r",
       "|==============                                                  |  22%    2 MB\r",
       "|===============                                                 |  23%    2 MB\r",
       "|===============                                                 |  24%    2 MB\r",
       "|================                                                |  25%    2 MB\r",
       "|================                                                |  26%    2 MB\r",
       "|=================                                               |  26%    2 MB\r",
       "|==================                                              |  27%    2 MB\r",
       "|==================                                              |  28%    2 MB\r",
       "|===================                                             |  29%    2 MB\r",
       "|===================                                             |  30%    2 MB\r",
       "|====================                                            |  31%    2 MB\r",
       "|====================                                            |  31%    2 MB\r",
       "|=====================                                           |  32%    2 MB\r",
       "|=====================                                           |  33%    2 MB\r",
       "|======================                                          |  34%    3 MB\r",
       "|======================                                          |  35%    3 MB\r",
       "|=======================                                         |  35%    3 MB\r",
       "|=======================                                         |  36%    3 MB\r",
       "|========================                                        |  37%    3 MB\r",
       "|=========================                                       |  38%    3 MB\r",
       "|=========================                                       |  39%    3 MB\r",
       "|==========================                                      |  40%    3 MB\r",
       "|==========================                                      |  40%    3 MB\r",
       "|===========================                                     |  41%    3 MB\r",
       "|===========================                                     |  42%    3 MB\r",
       "|============================                                    |  43%    3 MB\r",
       "|============================                                    |  44%    3 MB\r",
       "|=============================                                   |  45%    3 MB\r",
       "|=============================                                   |  45%    4 MB\r",
       "|==============================                                  |  46%    4 MB\r",
       "|==============================                                  |  47%    4 MB\r",
       "|===============================                                 |  48%    4 MB\r",
       "|================================                                |  49%    4 MB\r",
       "|================================                                |  50%    4 MB\r",
       "|=================================                               |  50%    4 MB\r",
       "|=================================                               |  51%    4 MB\r",
       "|==================================                              |  52%    4 MB\r",
       "|==================================                              |  53%    4 MB\r",
       "|===================================                             |  54%    4 MB\r",
       "|===================================                             |  55%    4 MB\r",
       "|====================================                            |  56%    4 MB\r",
       "|====================================                            |  56%    5 MB\r",
       "|=====================================                           |  57%    5 MB\r",
       "|======================================                          |  58%    5 MB\r",
       "|======================================                          |  59%    5 MB\r",
       "|=======================================                         |  60%    5 MB\r",
       "|=======================================                         |  61%    5 MB\r",
       "|========================================                        |  61%    5 MB\r",
       "|========================================                        |  62%    5 MB\r",
       "|=========================================                       |  63%    5 MB\r",
       "|=========================================                       |  64%    5 MB\r",
       "|==========================================                      |  65%    5 MB\r",
       "|===========================================                     |  66%    5 MB\r",
       "|===========================================                     |  67%    5 MB\r",
       "|============================================                    |  67%    5 MB\r",
       "|============================================                    |  68%    6 MB\r",
       "|=============================================                   |  69%    6 MB\r",
       "|=============================================                   |  70%    6 MB\r",
       "|==============================================                  |  71%    6 MB\r",
       "|==============================================                  |  72%    6 MB\r",
       "|===============================================                 |  72%    6 MB\r",
       "|===============================================                 |  73%    6 MB\r",
       "|================================================                |  74%    6 MB\r",
       "|=================================================               |  75%    6 MB\r",
       "|=================================================               |  76%    6 MB\r",
       "|==================================================              |  77%    6 MB\r",
       "|==================================================              |  78%    6 MB\r",
       "|===================================================             |  78%    6 MB\r",
       "|===================================================             |  79%    7 MB\r",
       "|====================================================            |  80%    7 MB\r",
       "|====================================================            |  81%    7 MB\r",
       "|=====================================================           |  82%    7 MB\r",
       "|======================================================          |  83%    7 MB\r",
       "|======================================================          |  83%    7 MB\r",
       "|=======================================================         |  84%    7 MB\r",
       "|=======================================================         |  85%    7 MB\r",
       "|========================================================        |  86%    7 MB\r",
       "|========================================================        |  87%    7 MB\r",
       "|=========================================================       |  88%    7 MB\r",
       "|=========================================================       |  89%    7 MB\r",
       "|==========================================================      |  89%    7 MB\r",
       "|==========================================================      |  90%    7 MB\r",
       "|===========================================================     |  91%    8 MB\r",
       "|============================================================    |  92%    8 MB\r",
       "|============================================================    |  93%    8 MB\r",
       "|=============================================================   |  94%    8 MB\r",
       "|=============================================================   |  94%    8 MB\r",
       "|==============================================================  |  95%    8 MB\r",
       "|==============================================================  |  96%    8 MB\r",
       "|=============================================================== |  97%    8 MB\r",
       "|=============================================================== |  98%    8 MB\r",
       "|================================================================|  99%    8 MB\r",
       "|=================================================================| 100%    8 MB\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R \n",
    "data_prior <- read_csv(\"data/for_composititional_analysis_prior.csv\")\n",
    "\n",
    "dict_prior <- data_prior %>% \n",
    "                        group_by(id, scenario) %>%\n",
    "                        summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%R -i maxs_prior_i,maxs_prior_k,maxs_prior_l\n",
    "\n",
    "maxs_prior <- data.frame(id=maxs_prior_i,kernel=maxs_prior_k,lml=maxs_prior_l)\n",
    "\n",
    "maxs_prior <- merge(x = maxs_prior, y = dict_prior, by = c(\"id\", \"id\"), all.x = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Temperature', 'Gym members', 'Salary', 'FB Friends', 'Rain',\n",
       "       'Sales'], \n",
       "      dtype='<U11')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%R maxs_prior$scenario %>% unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "maxs_prior_temperature <- maxs_prior %>% filter(scenario == \"Temperature\")\n",
    "maxs_prior_rain <- maxs_prior %>% filter(scenario == \"Rain\")\n",
    "maxs_prior_sales <- maxs_prior %>% filter(scenario == \"Sales\")\n",
    "maxs_prior_gym <- maxs_prior %>% filter(scenario == \"Gym members\")\n",
    "maxs_prior_salary <- maxs_prior %>% filter(scenario == \"Salary\")\n",
    "maxs_prior_fb <- maxs_prior %>% filter(scenario == \"FB Friends\")\n",
    "\n",
    "prop_temperature <- get_proportions(maxs_prior_temperature)\n",
    "prop_rain <- get_proportions(maxs_prior_rain)\n",
    "prop_sales <- get_proportions(maxs_prior_sales)\n",
    "prop_gym <- get_proportions(maxs_prior_gym)\n",
    "prop_salary <- get_proportions(maxs_prior_salary)\n",
    "prop_fb <- get_proportions(maxs_prior_fb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "p1 <- plot_proportions(prop_temperature, \"Temperature\", hide_x=TRUE)\n",
    "p2 <- plot_proportions(prop_rain, \"Rain\")\n",
    "p3 <- plot_proportions(prop_sales, \"Sales\", hide_x=TRUE, hide_y=TRUE)\n",
    "p4 <- plot_proportions(prop_gym, \"Gym members\", hide_y=TRUE)\n",
    "p5 <- plot_proportions(prop_salary, \"Salary\", hide_x=TRUE, hide_y=TRUE)\n",
    "p6 <- plot_proportions(prop_fb, \"FB Friends\", hide_y=TRUE)\n",
    "\n",
    "svg(\"Images/kernels_prior.svg\", width=8, height=4)\n",
    "multiplot(p1, p2, p3, p4, p5, p6, cols=3)\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the best kernel composition SSE versus those of `l` and `r`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_posterior_curve(cid):\n",
    "    cid = int(cid)\n",
    "    dataset = data_posterior\n",
    "    \n",
    "    # Filter the relevant data\n",
    "    filtered_data = dataset[dataset['f0'] == cid]\n",
    "    \n",
    "    # Get X and Y\n",
    "    x = filtered_data['f3']\n",
    "    y = filtered_data['f4']\n",
    "    \n",
    "    df = pd.DataFrame([x, y]).T\n",
    "    \n",
    "    df.columns=[\"x\", \"y\"]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_posterior_prediction(cid, kernel_name):\n",
    "    # Get the target values\n",
    "    x = Xpredictions\n",
    "    \n",
    "    y = results_posterior['predictions'][cid][kernel_name]['mean']\n",
    "    \n",
    "    y_var = results_posterior['predictions'][cid][kernel_name]['var']\n",
    "    \n",
    "    # Squeeze the matrices\n",
    "    x = np.squeeze(x); y = np.squeeze(y); y_var = np.squeeze(y_var); \n",
    "    \n",
    "    df = pd.DataFrame([x, y, y_var]).T\n",
    "    \n",
    "    df.columns=[\"x\", \"y\", \"y_var\"]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_y_value(df, x):\n",
    "    return df[df['x']==x]['y'].tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_SSE(dataframe1, dataframe2, minX = 365-31):\n",
    "    df1 = dataframe1[dataframe1['x'] > minX]\n",
    "    df2 = dataframe2[dataframe2['x'] > minX]\n",
    "    \n",
    "    sse = 0\n",
    "    \n",
    "    for x in df1['x'] :\n",
    "        error = get_y_value(df1, x) - get_y_value(df2, x)\n",
    "        sse += (error*error)\n",
    "        \n",
    "    return sse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"cid\", \"sse_l\", \"sse_r\", \"sse_best\"]\n",
    "\n",
    "sses = pd.DataFrame(columns = columns)\n",
    "\n",
    "for cid in np.unique(data_prior['f0']):\n",
    "    \n",
    "    if cid != 533:\n",
    "        cid = str(cid)\n",
    "\n",
    "        # Get the best kernel for the curve\n",
    "        best_kernel_name = results_prior['maxs'][cid][0][0]\n",
    "\n",
    "        # Gest the predictions of the l, r, and best kernel\n",
    "        prediction_l = get_posterior_prediction(cid, 'l')\n",
    "        prediction_r = get_posterior_prediction(cid, 'r')\n",
    "        prediction_best = get_posterior_prediction(cid, best_kernel_name)\n",
    "\n",
    "        # Get the actual values in the posterior condition\n",
    "        prediction = get_posterior_curve(cid)\n",
    "\n",
    "        # Calculate the Sum of squared errors\n",
    "        sse_l = compute_SSE(prediction, prediction_l)\n",
    "        sse_r = compute_SSE(prediction, prediction_r)\n",
    "        sse_best = compute_SSE(prediction, prediction_best)\n",
    "\n",
    "        results = pd.DataFrame([cid, sse_l, sse_r, sse_best]).T\n",
    "        results.columns = [\"cid\", \"sse_l\", \"sse_r\", \"sse_best\"]\n",
    "\n",
    "        sses = sses.append(results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cid                inf\n",
       "sse_l       244.618028\n",
       "sse_r        18.611459\n",
       "sse_best     42.572179\n",
       "dtype: float64"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sses.mean() / 10000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_posterior['predictions']['533']['p+r']['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the SSE for every prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEBUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_prior['maxs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['maxs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
