{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsed with column specification:\n",
      "cols(\n",
      "  .default = col_double(),\n",
      "  userId = col_character(),\n",
      "  age = col_character(),\n",
      "  datetime = col_character(),\n",
      "  gender = col_character(),\n",
      "  datetime_1 = col_character(),\n",
      "  stage = col_integer(),\n",
      "  scenario = col_character(),\n",
      "  subcondition = col_integer(),\n",
      "  pageIndex = col_integer(),\n",
      "  noiseIndex = col_integer(),\n",
      "  day0 = col_character(),\n",
      "  day1 = col_character(),\n",
      "  day2 = col_character(),\n",
      "  day3 = col_character(),\n",
      "  day4 = col_character(),\n",
      "  day5 = col_character(),\n",
      "  day6 = col_character(),\n",
      "  day7 = col_character(),\n",
      "  day8 = col_character(),\n",
      "  day9 = col_character()\n",
      "  # ... with 69 more columns\n",
      ")\n",
      "See spec(...) for full column specifications.\n",
      "Warning message in eval(substitute(expr), envir, enclos):\n",
      "\"NAs introduced by coercion\""
     ]
    }
   ],
   "source": [
    "source(\"tools.R\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(gridExtra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernel composition name change\n",
    "#l+r+p -> l+p+r\n",
    "#l+r*p -> l+p*r\n",
    "#l*r*p -> l*p*r\n",
    "\n",
    "readable_kernel <- function(current_kernel){\n",
    "    new_kernel <- current_kernel\n",
    "    \n",
    "    new_kernel <- ifelse(new_kernel == 'l+r+p', 'l+p+r', new_kernel)\n",
    "    new_kernel <- ifelse(new_kernel == 'l+r*p', 'l+p*r', new_kernel)\n",
    "    new_kernel <- ifelse(new_kernel == 'l*r*p', 'l*p*r', new_kernel)\n",
    "    \n",
    "    new_kernel <- gsub(\"\\\\*\", \"Ã—\", new_kernel)\n",
    "    \n",
    "    return(new_kernel)\n",
    "}\n",
    "\n",
    "# Get the range of a scenario\n",
    "get_range <- function(scenario_name) {\n",
    "    switch( scenario_name,\n",
    "            'Temperature' = c(-10, 40),\n",
    "            'Rain' = c(0, 100),\n",
    "            'Sales' = c(0, 5000),\n",
    "            'Gym members' = c(0, 50),\n",
    "            'Salary' = c(0, 50),\n",
    "            'FB Friends' = c(0, 1000))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_lmls <- function(prop_data, title='', scenario, hide_x=FALSE, hide_y=FALSE, red_border=TRUE) {\n",
    "    \n",
    "    # Best-fitting real-world data kernel composition\n",
    "    rw_lmls <- read_csv(\"data/real-world/to-plot.csv\")\n",
    "    red_kernel <- (rw_lmls %>%\n",
    "                    filter(scenario == !!scenario) %>%\n",
    "                    summarize(red_kernel = kernel[which.max(lml)]))$red_kernel\n",
    "    red_kernel <- readable_kernel(red_kernel)\n",
    "\n",
    "    plot <- prop_data %>%\n",
    "                ggplot(aes(x=kernel, y=value)) +\n",
    "                    geom_bar(stat='identity') +\n",
    "                    geom_bar(stat='identity', data=prop_data %>% filter(kernel == red_kernel), alpha=0, size=0.5, color=\"red\") +\n",
    "                    coord_cartesian (ylim=c(0, 1)) +\n",
    "                    #labs(title = title) +\n",
    "                    ggthemes::theme_few() +\n",
    "                    xlab(\"Kernel composition\") +\n",
    "                    ylab(\"Likelihood\") +\n",
    "                    geom_errorbar(aes(ymin=as.numeric(lo_ci), ymax=as.numeric(hi_ci)),\n",
    "                                      width=.3,\n",
    "                                      position=position_dodge(.9)) +\n",
    "                    scale_y_continuous(breaks = seq(0, 1, length.out=3)) +\n",
    "                    theme(axis.text.x = element_text(angle = 90,  vjust = 0.5, hjust=0),\n",
    "                          text = element_text(size=12, family=\"serif\"))\n",
    "\n",
    "    if(hide_x){\n",
    "        plot <- plot + theme(axis.title.x=element_blank())\n",
    "    }\n",
    "    if(hide_y){\n",
    "        plot <- plot + theme(axis.title.y=element_blank())\n",
    "    }\n",
    "    \n",
    "    return(plot)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_curves <- function(plot_data, plot_rwdata, ylab='', scenario, hide_x=FALSE, hide_y=FALSE) {\n",
    "\n",
    "    # Min and max value of the data to be shown\n",
    "    range_y <- get_range(scenario)\n",
    "    limits_y <- c( min(range_y[1], min(plot_data$value)), max(range_y[2], max(plot_data$value)))\n",
    "    \n",
    "    # Mean trend\n",
    "    trend <- plot_data %>% group_by(day) %>% summarize(mean_y = mean(value))\n",
    "    \n",
    "    # Plotting\n",
    "    plot <- plot_data %>%\n",
    "                ggplot(aes(x=day, y=value, group=id)) +\n",
    "                    geom_line(col=\"steelblue\", alpha=0.2) + # Participants' curves\n",
    "                    geom_line(data=plot_rwdata, aes(x=day, group=1), colour=\"red\", alpha=0.6) + # Real world data\n",
    "                    geom_line(data=trend, aes(x=day, y=mean_y, group=1), colour=\"black\") + # Mean trend\n",
    "                    #labs(title = title) +\n",
    "                    ggthemes::theme_few() +\n",
    "                    ylab(ylab) +\n",
    "                    scale_x_continuous(breaks = c(0, 365, 365*2, 365*3), labels=c('Y1', 'Y2', 'Y3', 'Y4')) +\n",
    "                    scale_y_continuous(breaks = seq(range_y[1], range_y[2], length.out=3), limits=limits_y) +\n",
    "                    theme(axis.text.x = element_text(angle = 90,  vjust = 0.5, hjust=0),\n",
    "                          axis.text.y = element_text(angle = 90,  vjust = 0.5, hjust=0.5),\n",
    "                          text = element_text(size=12, family=\"serif\"))\n",
    "\n",
    "    if(hide_x){\n",
    "        plot <- plot + theme(axis.title.x=element_blank())\n",
    "    }\n",
    "    if(hide_y){\n",
    "        plot <- plot + theme(axis.title.y=element_blank())\n",
    "    }\n",
    "    \n",
    "    return(plot)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prior: Kernel compositions bar plots\n",
    "\n",
    "##### Import and prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"Missing column names filled in: 'X1' [1]\"Parsed with column specification:\n",
      "cols(\n",
      "  X1 = col_integer(),\n",
      "  id = col_integer(),\n",
      "  pid = col_character(),\n",
      "  scenario = col_character(),\n",
      "  x = col_integer(),\n",
      "  y = col_double()\n",
      ")\n",
      "Warning message:\n",
      "\"Missing column names filled in: 'X1' [1]\"Parsed with column specification:\n",
      "cols(\n",
      "  X1 = col_integer(),\n",
      "  l = col_double(),\n",
      "  `l*p` = col_double(),\n",
      "  `l*p+r` = col_double(),\n",
      "  `l*r` = col_double(),\n",
      "  `l*r*p` = col_double(),\n",
      "  `l*r+p` = col_double(),\n",
      "  `l+p` = col_double(),\n",
      "  `l+r` = col_double(),\n",
      "  `l+r*p` = col_double(),\n",
      "  `l+r+p` = col_double(),\n",
      "  p = col_double(),\n",
      "  `p*r` = col_double(),\n",
      "  `p+r` = col_double(),\n",
      "  r = col_double()\n",
      ")\n",
      "Parsed with column specification:\n",
      "cols(\n",
      "  cid = col_integer(),\n",
      "  composition = col_character(),\n",
      "  white_added = col_character(),\n",
      "  second_exception = col_character()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "data_prior <- read_csv(\"data/for_composititional_analysis_prior.csv\")\n",
    "\n",
    "dict_prior <- data_prior %>%                        \n",
    "                        group_by(id, pid, scenario) %>%\n",
    "                        summarize()\n",
    "\n",
    "lmls_prior <- read_csv(\"output/lmls_prior.csv\")\n",
    "\n",
    "metadata_prior <- read_csv(\"output/metadata_prior.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metadata_prior <- metadata_prior %>%\n",
    "                        mutate( cid_composition = paste0(cid, composition) )\n",
    "\n",
    "metadata_prior$pid <- NULL\n",
    "metadata_prior$composition <- NULL\n",
    "\n",
    "kernels  <- c(\"l\", \"p\", \"r\", \"l+p\", \"l+r\", \"p+r\", \"l*r\", \"l*p\", \"p*r\", \"l+r+p\", \"l+r*p\", \"l*r+p\", \"l*p+r\", \"l*r*p\")\n",
    "\n",
    "lmls_prior<- lmls_prior %>% \n",
    "                gather(kernel, lml, kernels)\n",
    "\n",
    "colnames(lmls_prior) = c('id', 'kernel', 'lml')\n",
    "\n",
    "lmls_prior <- merge(x = lmls_prior, y = dict_prior, by = c(\"id\", \"id\"), all.x = TRUE)\n",
    "\n",
    "lmls_prior <- lmls_prior %>%\n",
    "                        mutate( cid_composition = paste0(id, kernel) )\n",
    "\n",
    "# Joining\n",
    "lmls_prior <- merge(x = lmls_prior, y = metadata_prior, by = c(\"cid_composition\", \"cid_composition\"), all.x = TRUE)\n",
    "lmls_prior$cid_composition <- NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernel composition name change\n",
    "lmls_prior$kernel <- readable_kernel(lmls_prior$kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Removes the GPs that failed to be optimized in the second time. The lmls that failed to be optimized are also removed.\n",
    "#Finaly, the lml_standard is calculated\n",
    "lmls_prior_f <- lmls_prior %>%\n",
    "                    filter(second_exception == 'False' & lml != -999999999) %>%\n",
    "                    group_by(pid, scenario) %>%\n",
    "                    mutate(lml_minus_min = lml - min(lml),\n",
    "                           lml_standard = lml_minus_min / (max(lml_minus_min) - min (lml_minus_min)))\n",
    "\n",
    "sds <- lmls_prior_f %>% \n",
    "            group_by(kernel, scenario) %>%\n",
    "            summarize(lo_bound = mean(lml) - 5*sd(lml), up_bound = mean(lml) + 5*sd(lml))\n",
    "\n",
    "sds$ks <- paste0(sds$kernel, sds$scenario)\n",
    "\n",
    "lmls_prior_f$ks <- paste0(lmls_prior_f$kernel, lmls_prior_f$scenario)\n",
    "\n",
    "sds$kernel <- NULL\n",
    "sds$scenario <- NULL\n",
    "\n",
    "lmls_prior_f <- merge(x = lmls_prior_f, y = sds, by = \"ks\", all.x = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prepare the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsed with column specification:\n",
      "cols(\n",
      "  scenario = col_character(),\n",
      "  kernel = col_character(),\n",
      "  lml = col_double()\n",
      ")\n",
      "Parsed with column specification:\n",
      "cols(\n",
      "  scenario = col_character(),\n",
      "  kernel = col_character(),\n",
      "  lml = col_double()\n",
      ")\n",
      "Parsed with column specification:\n",
      "cols(\n",
      "  scenario = col_character(),\n",
      "  kernel = col_character(),\n",
      "  lml = col_double()\n",
      ")\n",
      "Parsed with column specification:\n",
      "cols(\n",
      "  scenario = col_character(),\n",
      "  kernel = col_character(),\n",
      "  lml = col_double()\n",
      ")\n",
      "Parsed with column specification:\n",
      "cols(\n",
      "  scenario = col_character(),\n",
      "  kernel = col_character(),\n",
      "  lml = col_double()\n",
      ")\n",
      "Parsed with column specification:\n",
      "cols(\n",
      "  scenario = col_character(),\n",
      "  kernel = col_character(),\n",
      "  lml = col_double()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "normalize_bool = TRUE\n",
    "plot_bool      = TRUE\n",
    "\n",
    "lmls_prior_ff <- lmls_prior_f %>% \n",
    "            filter(lml > -10000) %>%\n",
    "            filter(lml > lo_bound & lml < up_bound)\n",
    "\n",
    "to_plot_prior <- lmls_prior_ff %>%\n",
    "            group_by(kernel, scenario) %>%\n",
    "            summarize(value = mean(lml),\n",
    "                      lo_ci = MeanCI(lml, method=\"boot\", type=\"norm\", na.rm=TRUE)['lwr.ci'],\n",
    "                      hi_ci = MeanCI(lml, method=\"boot\", type=\"norm\", na.rm=TRUE)['upr.ci'])\n",
    "\n",
    "# Remove single components\n",
    "to_plot_prior <- to_plot_prior %>%\n",
    "                filter(kernel != 'l', kernel != 'p', kernel != 'r')\n",
    "\n",
    "# Scaling the 'data to plot' to a 0-1 range\n",
    "min_v = min(to_plot_prior$value)\n",
    "range_v = max(to_plot_prior$value) - min(to_plot_prior$value)\n",
    "\n",
    "if(normalize_bool) {\n",
    "    #Normalization\n",
    "    to_plot_prior <- to_plot_prior %>%\n",
    "                    group_by( scenario ) %>%\n",
    "                    mutate( lo_ci = (lo_ci - min(value)) / (max(value) - min(value)),\n",
    "                            hi_ci = (hi_ci - min(value)) / (max(value) - min(value)),  \n",
    "                            value = (value - min(value)) / (max(value) - min(value)))\n",
    "}\n",
    "\n",
    "# Plotting magic\n",
    "to_plot_prior$kernel <- factor(to_plot_prior$kernel, levels=readable_kernel(kernels))\n",
    "\n",
    "lmls_temperature <- to_plot_prior %>% filter(scenario == \"Temperature\")\n",
    "lmls_rain <- to_plot_prior %>% filter(scenario == \"Rain\")\n",
    "lmls_sales <- to_plot_prior %>% filter(scenario == \"Sales\")\n",
    "lmls_gym <- to_plot_prior %>% filter(scenario == \"Gym members\")\n",
    "lmls_salary <- to_plot_prior %>% filter(scenario == \"Salary\")\n",
    "lmls_fb <- to_plot_prior %>% filter(scenario == \"FB Friends\")\n",
    "\n",
    "\n",
    "if (plot_bool) {\n",
    "    # Plots\n",
    "    p_temp   <- plot_lmls( lmls_temperature, scenario=\"Temperature\", hide_x=TRUE, hide_y=FALSE)\n",
    "    p_rain   <- plot_lmls( lmls_rain,        scenario=\"Rain\",        hide_x=TRUE, hide_y=FALSE)\n",
    "    p_sales  <- plot_lmls( lmls_sales,       scenario=\"Sales\",       hide_x=TRUE, hide_y=FALSE)\n",
    "    p_gym    <- plot_lmls( lmls_gym,         scenario=\"Gym members\", hide_x=TRUE, hide_y=FALSE)\n",
    "    p_salary <- plot_lmls( lmls_salary,      scenario=\"Salary\",      hide_x=TRUE, hide_y=FALSE)\n",
    "    p_fb     <- plot_lmls( lmls_fb,          scenario=\"FB Friends\",  hide_x=TRUE, hide_y=FALSE)\n",
    "\n",
    "    #pdf(\"Images/paper_images/kernels_priors_lmls_5sd.pdf\", width=8, height=4)\n",
    "    #multiplot(p1, p2, p3, p4, p5, p6, cols=3)\n",
    "    #dev.off()   \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prior: Curves (participant's data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsed with column specification:\n",
      "cols(\n",
      "  scenario = col_character(),\n",
      "  day = col_integer(),\n",
      "  value = col_double()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "mean_centering <- function(rwdata, dat, scenario) {\n",
    "    mean_rw <- rwdata %>% filter(scenario == !!scenario) %>% summarize(mv=mean(value))\n",
    "    \n",
    "    mean_dat <- dat %>% filter(scenario == !!scenario, condition == 'Prior') %>% summarize(mv=mean(value))    \n",
    "    \n",
    "    mean_dat$mv / mean_rw$mv\n",
    "}\n",
    "\n",
    "# Real-world data\n",
    "rwdata <- read_csv('data/real-world/splines.csv')\n",
    "\n",
    "rwdata$condition <- 'Prior' # Add column\n",
    "rwdata$id <- 1 #Create a new ID column\n",
    "rwdata <- filter(rwdata, day >= 31) # Filter out the initial days\n",
    "rwdata <- filter(rwdata, day <= 365*4 - 31) # Filter out the final days\n",
    "\n",
    "# Order\n",
    "rwdata$condition <- factor( rwdata$condition, levels = condition_names)\n",
    "rwdata$scenario <- factor( rwdata$scenario, levels = readable_scenarios)\n",
    "\n",
    "# Scale the values\n",
    "rwdata[rwdata$scenario == 'Rain', 'day'] <- rwdata[rwdata$scenario == 'Rain', 'day'] + (365/12) * 1.5 #Offset 1.5 months to the right\n",
    "\n",
    "# Mean centering\n",
    "for (s in readable_scenarios){\n",
    "    rwdata[rwdata$scenario == s, 'value'] <- rwdata[rwdata$scenario == s, 'value'] * mean_centering(rwdata, dat, s)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "curves_plot <- function(scenario_name, ...) {\n",
    "    dat %>% \n",
    "        filter(scenario==scenario_name, condition=='Prior') %>% \n",
    "        plot_curves(rwdata %>% filter(scenario==scenario_name), scenario=scenario_name, ylab=scenario_name, ...)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_temp_curves   <- curves_plot('Temperature', hide_x=TRUE, hide_y=FALSE)\n",
    "p_rain_curves   <- curves_plot('Rain',        hide_x=TRUE, hide_y=FALSE)\n",
    "p_sales_curves  <- curves_plot('Sales',       hide_x=TRUE, hide_y=FALSE)\n",
    "p_gym_curves    <- curves_plot('Gym members', hide_x=TRUE, hide_y=FALSE)\n",
    "p_salary_curves <- curves_plot('Salary',      hide_x=TRUE, hide_y=FALSE)\n",
    "p_fb_curves     <- curves_plot('FB Friends',  hide_x=TRUE, hide_y=FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>png:</strong> 2"
      ],
      "text/latex": [
       "\\textbf{png:} 2"
      ],
      "text/markdown": [
       "**png:** 2"
      ],
      "text/plain": [
       "png \n",
       "  2 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if(TRUE){\n",
    "    # Save/show\n",
    "    pdf(\"Images/paper_images/grid_plot_prior.pdf\", width=6, height=10)\n",
    "    grid.arrange(p_temp_curves,   p_temp, \n",
    "                 p_rain_curves,   p_rain, \n",
    "                 p_sales_curves,  p_sales, \n",
    "                 p_gym_curves,    p_gym, \n",
    "                 p_salary_curves, p_salary, \n",
    "                 p_fb_curves,     p_fb, \n",
    "                 ncol=2)\n",
    "    dev.off()   \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Posterior: Curves (participants' data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_curves_posterior <- function(plot_data, ylab='', scenario, hide_x=FALSE, hide_y=FALSE) {\n",
    "\n",
    "    # Min and max value of the data to be shown\n",
    "    range_y <- get_range(scenario)\n",
    "    limits_y <- c( min(range_y[1], min(plot_data$value)), max(range_y[2], max(plot_data$value)))\n",
    "    \n",
    "    # Mean trend\n",
    "    trend_1 <- plot_data %>% filter(condition=='Posterior-Positive') %>% group_by(day) %>% summarize(mean_y = mean(value))\n",
    "    trend_2 <- plot_data %>% filter(condition=='Posterior-Stable') %>%   group_by(day) %>% summarize(mean_y = mean(value))\n",
    "    trend_3 <- plot_data %>% filter(condition=='Posterior-Negative') %>% group_by(day) %>% summarize(mean_y = mean(value))\n",
    "    \n",
    "    # Plotting\n",
    "    plot <- plot_data %>%\n",
    "                ggplot(aes(x=day, y=value, group=id)) +\n",
    "                    # Curves:\n",
    "                    geom_line(data=plot_data %>% filter(condition=='Posterior-Positive'), col=\"steelblue\", alpha=0.1) +\n",
    "                    geom_line(data=plot_data %>% filter(condition=='Posterior-Stable'),   col=\"firebrick\", alpha=0.1) +\n",
    "                    geom_line(data=plot_data %>% filter(condition=='Posterior-Negative'), col=\"olivedrab\", alpha=0.1) +\n",
    "                    \n",
    "                    # Mean curves\n",
    "                    geom_line(data=trend_1, aes(x=day, y=mean_y, group=1), colour=\"blue\") +\n",
    "                    geom_line(data=trend_2, aes(x=day, y=mean_y, group=1), colour=\"red\") +\n",
    "                    geom_line(data=trend_3, aes(x=day, y=mean_y, group=1), colour=\"darkgreen\") +\n",
    "                    \n",
    "                    # Vertical line (end of evidence mark)\n",
    "                    geom_vline(aes(xintercept=365-31), colour='black') +\n",
    "    \n",
    "                    ggthemes::theme_few() +\n",
    "                    ylab(ylab) +\n",
    "                    scale_x_continuous(breaks = c(0, 365, 365*2, 365*3), labels=c('Y1', 'Y2', 'Y3', 'Y4')) +\n",
    "                    scale_y_continuous(breaks = seq(range_y[1], range_y[2], length.out=3), limits=limits_y) +\n",
    "                    theme(axis.text.x = element_text(angle = 90,  vjust = 0.5, hjust=0),\n",
    "                          axis.text.y = element_text(angle = 90,  vjust = 0.5, hjust=0.5),\n",
    "                          text = element_text(size=12, family=\"serif\"))\n",
    "\n",
    "    if(hide_x){\n",
    "        plot <- plot + theme(axis.title.x=element_blank())\n",
    "    }\n",
    "    if(hide_y){\n",
    "        plot <- plot + theme(axis.title.y=element_blank())\n",
    "    }\n",
    "    \n",
    "    return(plot)\n",
    "}\n",
    "    \n",
    "curves_plot_posterior <- function(scenario_name, ...) {\n",
    "    dat %>% \n",
    "        filter(scenario==scenario_name, condition!='Prior') %>% \n",
    "        plot_curves_posterior(scenario=scenario_name, ylab=scenario_name, ...)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_curves_temp <- curves_plot_posterior('Temperature', hide_x=TRUE, hide_y=FALSE)\n",
    "posterior_curves_rain <- curves_plot_posterior('Rain',        hide_x=TRUE, hide_y=FALSE)\n",
    "posterior_curves_sale <- curves_plot_posterior('Sales',       hide_x=TRUE, hide_y=FALSE)\n",
    "posterior_curves_gymm <- curves_plot_posterior('Gym members', hide_x=TRUE, hide_y=FALSE)\n",
    "posterior_curves_slry <- curves_plot_posterior('Salary',      hide_x=TRUE, hide_y=FALSE)\n",
    "posterior_curves_fbfr <- curves_plot_posterior('FB Friends',  hide_x=TRUE, hide_y=FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Posterior: Performance. Prediction against participant's results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importing the posterior kernel composition data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsed with column specification:\n",
      "cols(\n",
      "  id = col_integer(),\n",
      "  kernel = col_character(),\n",
      "  lml = col_double(),\n",
      "  white_added = col_logical(),\n",
      "  second_exception = col_logical()\n",
      ")\n",
      "Warning message:\n",
      "\"Missing column names filled in: 'X1' [1]\"Parsed with column specification:\n",
      "cols(\n",
      "  X1 = col_integer(),\n",
      "  id = col_integer(),\n",
      "  pid = col_character(),\n",
      "  scenario = col_character(),\n",
      "  x = col_integer(),\n",
      "  y = col_double(),\n",
      "  condition = col_character()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "lmls_posterior <- read_csv(\"output/full-bayesian-posterior/results_posterior_test_lmls.csv\")\n",
    "\n",
    "# To add the 'scenario' column\n",
    "data_posterior <- read_csv(\"data/for_composititional_analysis_posterior.csv\")\n",
    "\n",
    "dict_posterior <- data_posterior %>%                        \n",
    "                        group_by(id, pid, scenario) %>%\n",
    "                        summarize()\n",
    "\n",
    "lmls_posterior <- merge(x = lmls_posterior, y = dict_posterior, by = c(\"id\", \"id\"), all.x = TRUE)\n",
    "\n",
    "# Removing unusable data, and standardizing.\n",
    "lmls_posterior_f <- lmls_posterior %>%\n",
    "                    filter(second_exception == 'FALSE' & lml != -999999999) %>%\n",
    "                    group_by(pid, scenario) %>%\n",
    "                    mutate(lml_minus_min = lml - min(lml),\n",
    "                           lml_standard = lml_minus_min / (max(lml_minus_min) - min (lml_minus_min)))\n",
    "\n",
    "# Standard deviations calculation\n",
    "sds <- lmls_posterior_f %>% \n",
    "            group_by(kernel, scenario) %>%\n",
    "            summarize(lo_bound = mean(lml) - 5*sd(lml), up_bound = mean(lml) + 5*sd(lml))\n",
    "\n",
    "sds$ks <- paste0(sds$kernel, sds$scenario)\n",
    "\n",
    "lmls_posterior_f$ks <- paste0(lmls_posterior_f$kernel, lmls_posterior_f$scenario)\n",
    "\n",
    "sds$kernel <- NULL\n",
    "sds$scenario <- NULL\n",
    "\n",
    "lmls_posterior_f <- merge(x = lmls_posterior_f, y = sds, by = \"ks\", all.x = TRUE)\n",
    "\n",
    "lmls_posterior_ff <- lmls_posterior_f %>%\n",
    "            filter(lml > -10000) %>%\n",
    "            filter(lml > lo_bound & lml < up_bound)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Importing the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsed with column specification:\n",
      "cols(\n",
      "  pid = col_integer(),\n",
      "  composition = col_character(),\n",
      "  Xpredictions = col_double(),\n",
      "  predictions_mean = col_character(),\n",
      "  predictions_var = col_character()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Import the predictions\n",
    "predictions_csv <- read_csv('output/full-bayesian-posterior/results_posterior_test_predictions.csv')\n",
    "\n",
    "predictions <- predictions_csv %>%\n",
    "                    mutate(value = as.numeric(substring(predictions_mean, 2, nchar(predictions_mean)-1))) %>%\n",
    "                    select(cid = pid, kernel = composition, day = Xpredictions, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Merging and filtering the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequence of days to analyze:\n",
    "sequence = seq(365-31 + 2, 1426, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inner join. \n",
    "# This is the predictions data merged with the best performing (and filtered) kernels in the posterior condition\n",
    "pred <- merge( \n",
    "            # Predictions (full-Bayesian):\n",
    "            x = predictions %>%\n",
    "                    filter(day %in% sequence),\n",
    "\n",
    "            # Kernels after the filters:\n",
    "            y = lmls_posterior_ff %>%\n",
    "                    select(cid=id, pid, scenario, kernel, lml),\n",
    "\n",
    "            by = c('cid', 'kernel')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the predictions with the real participants' data\n",
    "all_pred_data <- merge(\n",
    "                # Predictions + Kernel posterior analysis:\n",
    "                x = pred,\n",
    "    \n",
    "                # Participant's data:\n",
    "                y = dat %>% \n",
    "                        filter(day >= 365-31, #remove evidence\n",
    "                               condition != 'Prior', #only Posterior conditions\n",
    "                               day %in% sequence) %>%\n",
    "                        select(pid = id, day, value_participant=value, scenario, condition, noise),\n",
    "    \n",
    "                by = c('pid', 'scenario', 'day')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Calculating the deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Normalized root mean squared deviation\n",
    "calculate_nrmsd <- function(value_prediction, value_participant) {\n",
    "    return (sqrt(sum((value_prediction - value_participant)^2) / length(value_prediction)) / (max(value_participant) - min(value_participant)))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_pred <- all_pred_data %>% \n",
    "                    group_by(pid, scenario, kernel, lml) %>%\n",
    "                    summarize(NRMSD = calculate_nrmsd(value, value_participant))\n",
    "\n",
    "results_pred <- merge(x = results_pred,\n",
    "\n",
    "                      # Mark the best-fitting kernel in each case\n",
    "                      y = results_pred %>%\n",
    "                            filter(nchar(kernel)!= 1) %>%\n",
    "                            group_by(pid, scenario) %>%\n",
    "                            mutate(is_max = lml == max(lml)) %>%\n",
    "                            filter(is_max) %>%\n",
    "                            select(pid, scenario, kernel, is_max),\n",
    "\n",
    "                      all.x = TRUE,\n",
    "                )\n",
    "\n",
    "results_pred$is_max <- !(is.na(results_pred$is_max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plotting the deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filtering in only Linear, RBF, and Best fitting compositions.\n",
    "to_plot_results_pred <- results_pred %>%\n",
    "                            filter(kernel == 'l' | kernel == 'r' | is_max)\n",
    "\n",
    "to_plot_results_pred$readable_kernel <- ifelse(to_plot_results_pred$is_max, 'best', to_plot_results_pred$kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_deviation <- function(to_plot_data, ylim) {\n",
    "    to_plot_data %>%\n",
    "        ggplot(aes(x=readable_kernel, y=NRMSD, group=readable_kernel)) +\n",
    "                        geom_boxplot(outlier.shape = 1,\n",
    "                                     outlier.size = 0.5) +\n",
    "                        \n",
    "                        scale_x_discrete(breaks = c('best', 'l', 'r'),\n",
    "                                         labels = c('Compositional', 'Linear', 'RBF')) +\n",
    "\n",
    "                        ylab(\"Error\") +\n",
    "                        \n",
    "                        scale_y_continuous(limits=ylim, breaks = seq(ylim[1], ylim[2], length.out=3)) +\n",
    "\n",
    "                        ggthemes::theme_few() +\n",
    "                        theme(text = element_text(size=12, family=\"serif\"),\n",
    "                                     plot.title = element_text(hjust = 0.5),\n",
    "                                     legend.position = \"none\",\n",
    "                                     axis.title.x = element_blank())\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_deviation_temp = plot_deviation( to_plot_results_pred %>% filter(scenario == 'Temperature'), ylim = c(0, 24))\n",
    "posterior_deviation_rain = plot_deviation( to_plot_results_pred %>% filter(scenario == 'Rain'),        ylim = c(0, 24))\n",
    "posterior_deviation_sale = plot_deviation( to_plot_results_pred %>% filter(scenario == 'Sales'),       ylim = c(0, 24))\n",
    "posterior_deviation_gymm = plot_deviation( to_plot_results_pred %>% filter(scenario == 'Gym members'), ylim = c(0, 24))\n",
    "posterior_deviation_slry = plot_deviation( to_plot_results_pred %>% filter(scenario == 'Salary'),      ylim = c(0, 24))\n",
    "posterior_deviation_fbfr = plot_deviation( to_plot_results_pred %>% filter(scenario == 'FB Friends'),  ylim = c(0, 24))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Second grid plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"Removed 4 rows containing non-finite values (stat_boxplot).\"Warning message:\n",
      "\"Removed 6 rows containing non-finite values (stat_boxplot).\"Warning message:\n",
      "\"Removed 7 rows containing non-finite values (stat_boxplot).\"Warning message:\n",
      "\"Removed 5 rows containing non-finite values (stat_boxplot).\"Warning message:\n",
      "\"Removed 17 rows containing non-finite values (stat_boxplot).\"Warning message:\n",
      "\"Removed 8 rows containing non-finite values (stat_boxplot).\""
     ]
    },
    {
     "data": {
      "text/html": [
       "<strong>png:</strong> 2"
      ],
      "text/latex": [
       "\\textbf{png:} 2"
      ],
      "text/markdown": [
       "**png:** 2"
      ],
      "text/plain": [
       "png \n",
       "  2 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if(TRUE){\n",
    "    pdf(\"Images/paper_images/grid_plot_posterior.pdf\", width=6, height=10)\n",
    "    multiplot(  posterior_curves_temp,\n",
    "                posterior_curves_rain,\n",
    "                posterior_curves_sale,\n",
    "                posterior_curves_gymm,\n",
    "                posterior_curves_slry,\n",
    "                posterior_curves_fbfr,\n",
    "              \n",
    "                posterior_deviation_temp,\n",
    "                posterior_deviation_rain,\n",
    "                posterior_deviation_sale,\n",
    "                posterior_deviation_gymm,\n",
    "                posterior_deviation_slry,\n",
    "                posterior_deviation_fbfr,\n",
    "                \n",
    "                cols = 2)\n",
    "    dev.off()   \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trend damping\n",
    "##### Goal: Proportion of damped predictions. Participants vs GP Predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
